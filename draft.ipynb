{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://m.facebook.com/groups/DeepNetGroup/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import selenium\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  Returns the first element found that has an attribute containing given pattern \n",
    "  params:\n",
    "    - elements: an iterable containing the Webdriver elements\n",
    "    - attribute: The attribute of the html element where to check for pattern\n",
    "    - pattern: a string to verify if it is in attribute\n",
    "  returns:\n",
    "    - html element if its attribute contains the pattern\n",
    "    - None else\n",
    "\"\"\" \n",
    "\n",
    "def get_element_with_pattern_in_attribute(elements, attribute, pattern):\n",
    "    els = []\n",
    "    for element in elements:\n",
    "        try:\n",
    "            if pattern in element.get_attribute(attribute):\n",
    "                els.append(element)\n",
    "        except:\n",
    "            pass\n",
    "    return els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "fp = webdriver.FirefoxProfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox(firefox_profile=fp)\n",
    "browser.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PAGE_FETCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Page 0\n",
      "14\n",
      "Page 1\n",
      "19\n",
      "Page 2\n",
      "24\n",
      "Page 3\n",
      "31\n",
      "Page 4\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "\n",
    "\n",
    "root = browser.find_element_by_id(\"m_group_stories_container\")\n",
    "els = get_element_with_pattern_in_attribute(root.find_elements_by_tag_name(\"div\"), \"role\", \"article\")\n",
    "\n",
    "for el in els: \n",
    "    soup = BeautifulSoup(el.get_attribute(\"innerHTML\"), 'html.parser')\n",
    "    aa = soup.find_all(lambda x: x.has_attr('data-ft'))\n",
    "    posts.append(aa)\n",
    "    \n",
    "print(len(posts))\n",
    "\n",
    "for i in range(MAX_PAGE_FETCH):\n",
    "\n",
    "    wait = WebDriverWait(browser, 10)\n",
    "    timeline = wait.until(EC.presence_of_element_located((By.ID, 'm_group_stories_container')))\n",
    "  \n",
    "    #spans = \n",
    "    print(f\"Page {i}\") \n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    for span in browser.find_elements_by_tag_name(\"span\"):\n",
    "        if \"See More Posts\" in span.text:\n",
    "            break\n",
    "    span.click()\n",
    "\n",
    "    root = browser.find_element_by_id(\"m_group_stories_container\")\n",
    "    els = get_element_with_pattern_in_attribute(root.find_elements_by_tag_name(\"div\"), \"role\", \"article\")\n",
    "   \n",
    "    for el in els: \n",
    "        soup = BeautifulSoup(el.get_attribute(\"innerHTML\"), 'html.parser')\n",
    "        aa = soup.find_all(lambda x: x.has_attr('data-ft'))\n",
    "        posts.append(aa)\n",
    "    print(len(posts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi all, I have doubt regarding CNN image classifiers which use softmax at the last layer. Let's say I have trained a CNN to classify cars, bikes and planes. So whenever I give it an image to classify, it gives out an array of probabilities for each class and they all add up to one. For example I give it an image of a ship, it will still give out some probability of being cars, bikes or planes. So my question is how can I train a CNN in such a way that it doesn't predict anything from the three... More\n",
      "\n",
      "2 hrs12 · Like · 14 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "I spoke to AI researcher Alex Bates about his book \"Augmented Mind,\" and why we need to rethink our perspective on AI as a complement and not a replacement for human intelligence.\n",
      "\n",
      "TechTalksAugmented Mind: Why we need a different perspective on AIAugmented Mind: Why we need a different perspective on AIbdtechtalks.com\n",
      "\n",
      "Augmented Mind: Why we need a different perspective on AI\n",
      "\n",
      "Augmented Mind: Why we need a different perspective on AIbdtechtalks.com\n",
      "\n",
      "3 hrs33 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Augmented Mind: Why we need a different perspective on AI\n",
      "\n",
      "Augmented Mind: Why we need a different perspective on AIbdtechtalks.com\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "How I used K-means Clustering to analyze Uber ride-sharing data. Practical application of Machine learning. I've published this article on Medium and I'd be happy to know your feedback. \n",
      "\n",
      "How does Uber use clustering?towardsdatascience.com\n",
      "\n",
      "15 hrs37 · Like · 2 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "We know Saturday is over but here's a book by Jeremy Howard that I think our members would be interested to pre order https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527\n",
      "\n",
      "\n",
      "\n",
      "9 hrs336 · Like · 7 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Suggest some job portals for data scientist and similar roles. I have recently completed my online certifications and  I have no experience. Also suggest some tips to get placed quickly.\n",
      "\n",
      "Yesterday at 5:38 PM6 · Like · 2 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Hi folks, I am currently working on a project that deals with multi-modal inputs. A part of the data contains tabular data having a shape of (85195, 20) and along with that, I have 100 images. The tabular data contains repetitions of the images hence it is much bigger in terms of rows.  I am reaching out to have your suggestions regarding designing the input pipelines to handle such data. Thank you for help in advance.\n",
      "\n",
      "Yesterday at 12:15 PM7 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Hi all, I have doubt regarding CNN image classifiers which use softmax at the last layer. Let's say I have trained a CNN to classify cars, bikes and planes. So whenever I give it an image to classify, it gives out an array of probabilities for each class and they all add up to one. For example I give it an image of a ship, it will still give out some probability of being cars, bikes or planes. So my question is how can I train a CNN in such a way that it doesn't predict anything from the three... More\n",
      "\n",
      "2 hrs12 · Like · 14 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "I spoke to AI researcher Alex Bates about his book \"Augmented Mind,\" and why we need to rethink our perspective on AI as a complement and not a replacement for human intelligence.\n",
      "\n",
      "TechTalksAugmented Mind: Why we need a different perspective on AIAugmented Mind: Why we need a different perspective on AIbdtechtalks.com\n",
      "\n",
      "Augmented Mind: Why we need a different perspective on AI\n",
      "\n",
      "Augmented Mind: Why we need a different perspective on AIbdtechtalks.com\n",
      "\n",
      "3 hrs33 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Augmented Mind: Why we need a different perspective on AI\n",
      "\n",
      "Augmented Mind: Why we need a different perspective on AIbdtechtalks.com\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "How I used K-means Clustering to analyze Uber ride-sharing data. Practical application of Machine learning. I've published this article on Medium and I'd be happy to know your feedback. \n",
      "\n",
      "How does Uber use clustering?towardsdatascience.com\n",
      "\n",
      "15 hrs37 · Like · 2 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "We know Saturday is over but here's a book by Jeremy Howard that I think our members would be interested to pre order https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527\n",
      "\n",
      "\n",
      "\n",
      "9 hrs336 · Like · 7 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Suggest some job portals for data scientist and similar roles. I have recently completed my online certifications and  I have no experience. Also suggest some tips to get placed quickly.\n",
      "\n",
      "Yesterday at 5:38 PM6 · Like · 2 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Hi folks, I am currently working on a project that deals with multi-modal inputs. A part of the data contains tabular data having a shape of (85195, 20) and along with that, I have 100 images. The tabular data contains repetitions of the images hence it is much bigger in terms of rows.  I am reaching out to have your suggestions regarding designing the input pipelines to handle such data. Thank you for help in advance.\n",
      "\n",
      "Yesterday at 12:15 PM7 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "TechTalksWhat is ethical AI?What is ethical AI?bdtechtalks.com\n",
      "\n",
      "What is ethical AI?\n",
      "\n",
      "What is ethical AI?bdtechtalks.com\n",
      "\n",
      "Yesterday at 2:15 PM41 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "What is ethical AI?\n",
      "\n",
      "What is ethical AI?bdtechtalks.com\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "#datascientists, #python developers: Join our live #webinar on Jan 21, 2020, @ 11:30 AM PST, where Baha Abu Nojaim, https://www.baseet.ai co-founder, discusses how to prototype, build, and deploy AI-POWERED apps in minutes using pre-trained models, apps and visual Baseet's drag and drop app builder.... More\n",
      "\n",
      "baseet.ai – The most comprehensive, low-code deep learning platform to design, prototype, train, and deploy models in minutes.baseet.ai\n",
      "\n",
      "18 hrs6 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "\"Deep machine learning method can predict molecular wave functions and electronic properties of moleculesThis algorithm could drastically speed-up future simulation efforts in the design of drug molecules or new materials\"\n",
      "\n",
      "Artificial Intelligence System Learns the Fundamental Laws of Quantum Mechanicsscitechdaily.com\n",
      "\n",
      "2 hrs18 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Short post about BERT and its impact on NLP and other NLP papers - \n",
      "\n",
      "2019 — Year of BERT and Transformertowardsdatascience.com\n",
      "\n",
      "2 hrs9 · Like · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "https://www.linkedin.com/pulse/neural-networks-van-der-pol-oscillator-using-matlab-alshikh-khalil #matlab #deeplearning\n",
      "\n",
      "Neural Networks for van der Pol Oscillator using Matlablinkedin.com\n",
      "\n",
      "3 hrs6 · Like · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "https://youtu.be/2UlBFiL6noU\n",
      "\n",
      "Neon, Samsung’s AI-powered avatar is world’s first ‘Artificial Human’youtube.com\n",
      "\n",
      "January 10 at 5:44 PM233 · Like · 33 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Here's the video of the AI debate between Yoshua Bengio and Gary Marcus from earlier today. This is the cleaned up YouTube version: https://www.youtube.com/watch?v=pKgseaENkAU Here's the high-level outline of the debate: 0:00 - Gary Marcus opening statement 22:13 - Yoshua Bengio opening statement... More\n",
      "\n",
      "AI Debate 2019: Yoshua Bengio vs Gary Marcusyoutube.com\n",
      "\n",
      "December 24, 2019 at 5:46 AM225 · Like · 8 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Hello! It's Saturday.  Time to post any $-related post including paid conferences, events and products.  You may also recruit and search for jobs.  As long as they are relevant to AI/DL, we will consider to approve them.  Have Fun! Arthur Chan\n",
      "\n",
      "Yesterday at 5:10 PM16 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Hi everyone! Has anyone here worked with company related data broken down by gender (such as company benefits, number of employees of each gender at the different departments etc) for their AI projects and knows where I could find such data?\n",
      "\n",
      "January 9 at 11:06 PM6 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "In this video, I discuss the theory and math behind artificial neurons. Once we get a solid understanding of artificial neurons, I move on to implementation. I code a simple artificial neuron from scratch in Python. The series “Deep Learning (for Audio) with Python” aims to teach Deep Learning from... More\n",
      "\n",
      "3- Implementing an artificial neuron from scratchyoutube.com\n",
      "\n",
      "Yesterday at 5:04 PM79 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Dear Waikit, Arthur and all, Find out awesome AI and Deep Learning articles on Computer Vision News of January (with codes!) Subscription is free! Enjoy! Ron RSIP Vision #ArtificialIntelligence #AI #ComputerVision #DeepLearning #MedicalImaging\n",
      "\n",
      "Computer Vision News - January 2020rsipvision.com\n",
      "\n",
      "January 9 at 2:31 PM18 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "What is your opinion on this? \n",
      "\n",
      "Rethinking Business Strategy in the Age of AIhbswk.hbs.edu\n",
      "\n",
      "January 9 at 11:20 PM36 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Several of us on the AI/DL list, including Adam Milton-Barker and Amitā Kapoor, are starting a non-profit organization to develop AI technologies for leukemia research. This is a nice example of people meeting on this list to start new projects. Please spread the word, and help us achieve our... More\n",
      "\n",
      "Help Fund A Leukemia AI Research Foundationindiegogo.com\n",
      "\n",
      "19 hrs48 · Like · 2 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Computers are getting more creative. But can they write rap lyrics? This is fun and cool work with friends and colleagues at ETH Zurich, Google, MIT, and Musixmatch, that explains AI-generated rap lyrics, plus a demo song by PomDP the PhD rapper with lyrics written by artificial intelligence. \n",
      "\n",
      "Generating rap lyrics with AIblog.musixmatch.com\n",
      "\n",
      "Yesterday at 5:01 PM61 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "CALL FOR PAPERSThe 2nd International Workshop on  Machine Learning for NextGeneration Systems and Networks (MLNGSN'2020)to be held in conjunction with IEEE ISNCC 202016-18 June 2020, Montreal, Canada.http://www.isncc-conf.org/workshops/mlngsnDear Colleagues,We are pleased to invite you to submit... More\n",
      "\n",
      "MLNGSN - ISNCC2020isncc-conf.org\n",
      "\n",
      "21 hrs6 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "https://thegradient.pub/an-epidemic-of-ai-misinformation/\n",
      "\n",
      "An Epidemic of AI Misinformationthegradient.pub\n",
      "\n",
      "January 10 at 2:50 PM49 · Like · 4 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "LEEDS Uni: Lecturer or Associate Professor, Artificial Intelligence and Data Science, deadline 5 Feb 2020 https://www.jobs.ac.uk/job/BXU092/lecturer-or-associate-professor-in-computer-science£41-59K p.a. full-time permanent post, deadline for applications: 5.2.2020we are seeking outstanding... More\n",
      "\n",
      "Lecturer or Associate Professor in Computer Science at University of Leedsjobs.ac.uk\n",
      "\n",
      "21 hrs22 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Immortality is too far. We still can not cure, cancer, diabetic, AIDS and many others diseases \n",
      "\n",
      "Baidu’s Robin Li Talks About Immortality Through AI In His Keynote Speechanalyticsindiamag.com\n",
      "\n",
      "January 10 at 3:13 AM40 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Dear Researchers,  We humbly request you to inform others to submit papers by 31 Jan. 2020.  IVPR: http://cennser.org/IVPR ICIEV: http://cennser.org/ICIEV ABC: https://abc-research.github.io/ Please kindly print the PDF CFP and paste on your notice boards, etc. Also, if possible, share in FB and... More\n",
      "\n",
      "4th IVPR: Intl. Conf. on Imaging, Vision & Pattern Recognitioncennser.org\n",
      "\n",
      "15 hrs7 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "[Saturday Post] List of Free Artificial Intelligence, Machine Learning, Data Science, Deep Learning, Mathematics, Python Programming Resources. (Updated every week) \n",
      "\n",
      "Free AI Resources | MarkTechPostmarktechpost.com\n",
      "\n",
      "Yesterday at 5:38 PM212 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Why the percentage difference in different country? And i hope it is developed for other cancer detection \n",
      "\n",
      "Google AI system can surpass human experts in spotting breast cancer, study findsusatoday.com\n",
      "\n",
      "January 8 at 10:50 PM265 · Like · 12 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "CSAIL - MITHappy birthday to Donald Knuth, whose \"Art of Computer Programming\" books have led many to call him the \"father of the analysis of algorithms.\" (photo: @CodeWisdom)\n",
      "\n",
      "Happy birthday to Donald Knuth, whose \"Art of Computer Programming\" books have led many to call him the \"father of the analysis of algorithms.\" (photo: @CodeWisdom)\n",
      "\n",
      "\n",
      "\n",
      "Yesterday at 5:08 PM85 · Like · 2 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Happy birthday to Donald Knuth, whose \"Art of Computer Programming\" books have led many to call him the \"father of the analysis of algorithms.\" (photo: @CodeWisdom)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "[Ads] Get your FREE Data science Curriculum now by subscribing to our newsletter! It comes in a form of an infographic with recommended courses and timeline to build up your data science skills. Limited time only! Subscribe now at https://twitter.com/selflearnds or find us by searching... More\n",
      "\n",
      "\n",
      "\n",
      "18 hrs3 · Like · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in posts:\n",
    "#    print(post[0].text)\n",
    "#    print(post[-1].text)\n",
    "    for el in post:\n",
    "        print(el.text)\n",
    "        print()\n",
    "    print(\"\\n{}\\n\".format(42*\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: The element reference of <span id=\"u_0_1\" class=\"db cg\"> is stale; either the element is no longer attached to the DOM, it is not in the current frame context, or the document has been refreshed\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-d4781e77aa22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"See More Posts\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/facebook-rss/venv/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/facebook-rss/venv/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/facebook-rss/venv/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/Documents/facebook-rss/venv/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: The element reference of <span id=\"u_0_1\" class=\"db cg\"> is stale; either the element is no longer attached to the DOM, it is not in the current frame context, or the document has been refreshed\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "els = get_element_with_pattern_in_attribute(browser.find_elements_by_tag_name(\"div\"), \"role\", \"article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_parser = {\n",
    "    0: lambda x: x,\n",
    "    1: lambda x: x,\n",
    "    2: lambda x: x\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_date_format(input_string):\n",
    "    month_list = [\n",
    "        \"January\",\n",
    "        \"February\",\n",
    "        \"March\",\n",
    "        \"April\",\n",
    "        \"May\",\n",
    "        \"June\",\n",
    "        \"July\",\n",
    "        \"August\",\n",
    "        \"September\",\n",
    "        \"October\",\n",
    "        \"November\",\n",
    "        \"December\",\n",
    "    ]\n",
    "    \n",
    "    for month in month_list:\n",
    "        if input_string.startswith(month):\n",
    "            if \",\" in input_string:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        elif \"Just now\" in input_string:\n",
    "            return datetime.datetime.now()\n",
    "        elif \"Yesterday\" in input_string:\n",
    "            return 3\n",
    "        elif \"hrs\" in input_string:\n",
    "            return 4\n",
    "        elif \"mins\" in input_string:\n",
    "            return 5\n",
    "        elif \"hr\" in input_string:\n",
    "            return 6\n",
    "        elif \"min\" in input_string:\n",
    "            return 7\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = \"^(\\w+) (\\d+), (\\d+) at (\\d+):(\\d+) ([APM]+)(\\d+).{3}Like.{3}(\\d+)\"\n",
    "r1 = \"^(\\w+) (\\d+) at (\\d+):(\\d+) ([APM]+)(\\d+).{3}Like.{3}(\\d+)\"\n",
    "r3 = \"Yesterday at (\\d+):(\\d+) ([AMP]+)(\\d+) .? Like .? (\\d+)\"\n",
    "r4 = \"(\\d+) hrs(\\d+) .? Like .? (\\d+)\"\n",
    "r5 = \"(\\d+) mins(\\d+) .? Like .? (\\d+)\"\n",
    "r6 = \"1 hr(\\d+) .? Like .? (\\d+)\"\n",
    "r7 = \"1 min(\\d+) .? Like .? (\\d+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 19 2019 1 31 PM\n",
      "2019-03-19 13:31:00\n",
      "360 Likes, 3 comments\n"
     ]
    }
   ],
   "source": [
    "p = re.compile(r0)\n",
    "m = p.match('March 19, 2019 at 1:31 PM360 · Like · 3 Comments · Full Story')\n",
    "#print(m.group(1), m.group(2), m.group(3), m.group(4), m.group(5), m.group(6))\n",
    "\n",
    "month = m.group(1)\n",
    "day = m.group(2) if len(m.group(2)) == 2 else \"0\" + m.group(2)\n",
    "year = m.group(3)\n",
    "hour = m.group(4) if len(m.group(4)) == 2 else \"0\" + m.group(4)\n",
    "minutes = m.group(5) if len(m.group(5)) == 2 else \"0\" + m.group(5)\n",
    "am_pm = m.group(6)\n",
    "\n",
    "string = f\"{month} {day} {year} {hour} {minutes} {am_pm}\"\n",
    "date = datetime.datetime.strptime(string, \"%B %d %Y %I %M %p\")\n",
    "print(date)\n",
    "print(f\"{m.group(7)} Likes, {m.group(8)} comments\")\n",
    "#datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 9 11 20 PM 36\n",
      "2020-01-09 23:20:00\n",
      "36 Likes, 3 comments\n"
     ]
    }
   ],
   "source": [
    "p = re.compile(r1)\n",
    "m = p.match('January 9 at 11:20 PM36 · Like · 3 Comments · Full Story')\n",
    "print(m.group(1), m.group(2), m.group(3), m.group(4), m.group(5), m.group(6))\n",
    "\n",
    "month = m.group(1)\n",
    "day = m.group(2) if len(m.group(2)) == 2 else \"0\" + m.group(2)\n",
    "year = datetime.datetime.now().year\n",
    "hour = m.group(3) if len(m.group(3)) == 2 else \"0\" + m.group(3)\n",
    "minutes = m.group(4) if len(m.group(4)) == 2 else \"0\" + m.group(4)\n",
    "am_pm = m.group(5)\n",
    "\n",
    "string = f\"{month} {day} {year} {hour} {minutes} {am_pm}\"\n",
    "date = datetime.datetime.strptime(string, \"%B %d %Y %I %M %p\")\n",
    "print(date)\n",
    "print(f\"{m.group(6)} Likes, {m.group(7)} comments\")\n",
    "#datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 15 PM 7 3\n",
      "2020-01-11 12:15:00\n",
      "7 Likes, 3 comments\n"
     ]
    }
   ],
   "source": [
    "p = re.compile(r3)\n",
    "m = p.match('Yesterday at 12:15 PM7 · Like · 3 Comments · Full Story')\n",
    "print(m.group(1), m.group(2), m.group(3), m.group(4), m.group(5))\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "month = str(today.month)\n",
    "month = month if len(month) == 2 else \"0\" + month\n",
    "day = str(today.day)\n",
    "day = day if len(day) == 2 else \"0\" + day\n",
    "\n",
    "year = datetime.datetime.now().year\n",
    "hour = m.group(1) if len(m.group(1)) == 2 else \"0\" + m.group(1)\n",
    "minutes = m.group(2) if len(m.group(2)) == 2 else \"0\" + m.group(2)\n",
    "am_pm = m.group(3)\n",
    "\n",
    "string = f\"{month} {day} {year} {hour} {minutes} {am_pm}\"\n",
    "date = datetime.datetime.strptime(string, \"%m %d %Y %I %M %p\")\n",
    "date += datetime.timedelta(days=-1)\n",
    "print(date)\n",
    "print(f\"{m.group(4)} Likes, {m.group(5)} comments\")\n",
    "#datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 60 3\n",
      "2020-01-12 01:34:47.119272\n",
      "60 Likes, 3 comments\n"
     ]
    }
   ],
   "source": [
    "p = re.compile(r4)\n",
    "m = p.match('22 hrs60 · Like · 3 Comments · Full Story')\n",
    "print(m.group(1), m.group(2), m.group(3))\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "date = today + datetime.timedelta(hours=-int(m.group(1)))\n",
    "print(date)\n",
    "print(f\"{m.group(2)} Likes, {m.group(3)} comments\")\n",
    "#datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 60 3\n",
      "2020-01-12 23:15:25.636513\n",
      "60 Likes, 3 comments\n"
     ]
    }
   ],
   "source": [
    "p = re.compile(r5)\n",
    "m = p.match('22 mins60 · Like · 3 Comments · Full Story')\n",
    "print(m.group(1), m.group(2), m.group(3))\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "date = today + datetime.timedelta(minutes=-int(m.group(1)))\n",
    "print(date)\n",
    "print(f\"{m.group(2)} Likes, {m.group(3)} comments\")\n",
    "#datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1\n",
      "2020-01-12 22:49:35.912713\n",
      "6 Likes, 1 comments\n"
     ]
    }
   ],
   "source": [
    "p = re.compile(r6)\n",
    "m = p.match('1 hr6 · Like · 1 Comment · Full Story')\n",
    "print(m.group(1), m.group(2))\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "date = today + datetime.timedelta(hours=-1)\n",
    "print(date)\n",
    "print(f\"{m.group(1)} Likes, {m.group(2)} comments\")\n",
    "#datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1\n",
      "2020-01-12 23:41:18.408037\n",
      "6 Likes, 1 comments\n"
     ]
    }
   ],
   "source": [
    "p = re.compile(r7)\n",
    "m = p.match('1 min6 · Like · 1 Comment · Full Story')\n",
    "print(m.group(1), m.group(2))\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "date = today + datetime.timedelta(minutes=-1)\n",
    "print(date)\n",
    "print(f\"{m.group(1)} Likes, {m.group(2)} comments\")\n",
    "#datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.utils import formatdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sun, 12 Jan 2020 21:49:35 -0000'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatdate(float(date.strftime('%s')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 12, 29, 23, 13, 32, 923606)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today + datetime.timedelta(days=-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAQ is here! Ask basic questions at https://goo.gl/M8Kx4J (The second Announcement post.)] [Use the Group Discussion thread. You can find it in Announcements.]We are the largest and the most active FB group for Artificial Intelligence/Deep Learning, or AIDL. Please scroll down & search for the FAQ... More\n",
      "\n",
      "Arthur Chan > ‎Artificial Intelligence & Deep Learning#faqthread. Here is the FAQ thread.  All discussion on basic questions such as \"How should I start deep learning?\" will direct here.  Here are some classics: \"How do I learn deep learning/AI?\" - See Q2-Q4.  \"What programming language should I use?\" - See Q10 \"I want to build a chat bot? How do I start\" - See Q19 \"Can you suggest some ideas for my projects/thesis/courses?\" - See Q20 Note that the Pinned Post FAQ is an invaluable resource.  So consider to read it before you ask any question on the... More\n",
      "\n",
      "#faqthread. Here is the FAQ thread.  All discussion on basic questions such as \"How should I start deep learning?\" will direct here.  Here are some classics: \"How do I learn deep learning/AI?\" - See Q2-Q4.  \"What programming language should I use?\" - See Q10 \"I want to build a chat bot? How do I start\" - See Q19 \"Can you suggest some ideas for my projects/thesis/courses?\" - See Q20 Note that the Pinned Post FAQ is an invaluable resource.  So consider to read it before you ask any question on the... More\n",
      "\n",
      "March 19, 2019 at 1:31 PM360 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "#faqthread. Here is the FAQ thread.  All discussion on basic questions such as \"How should I start deep learning?\" will direct here.  Here are some classics: \"How do I learn deep learning/AI?\" - See Q2-Q4.  \"What programming language should I use?\" - See Q10 \"I want to build a chat bot? How do I start\" - See Q19 \"Can you suggest some ideas for my projects/thesis/courses?\" - See Q20 Note that the Pinned Post FAQ is an invaluable resource.  So consider to read it before you ask any question on the... More\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "What is your opinion on this? \n",
      "\n",
      "Rethinking Business Strategy in the Age of AIhbswk.hbs.edu\n",
      "\n",
      "January 9 at 11:20 PM36 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Several of us on the AI/DL list, including Adam Milton-Barker and Amitā Kapoor, are starting a non-profit organization to develop AI technologies for leukemia research. This is a nice example of people meeting on this list to start new projects. Please spread the word, and help us achieve our... More\n",
      "\n",
      "Help Fund A Leukemia AI Research Foundationindiegogo.com\n",
      "\n",
      "16 hrs41 · Like · 2 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Computers are getting more creative. But can they write rap lyrics? This is fun and cool work with friends and colleagues at ETH Zurich, Google, MIT, and Musixmatch, that explains AI-generated rap lyrics, plus a demo song by PomDP the PhD rapper with lyrics written by artificial intelligence. \n",
      "\n",
      "Generating rap lyrics with AIblog.musixmatch.com\n",
      "\n",
      "22 hrs60 · Like · 3 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "CALL FOR PAPERSThe 2nd International Workshop on  Machine Learning for NextGeneration Systems and Networks (MLNGSN'2020)to be held in conjunction with IEEE ISNCC 202016-18 June 2020, Montreal, Canada.http://www.isncc-conf.org/workshops/mlngsnDear Colleagues,We are pleased to invite you to submit... More\n",
      "\n",
      "MLNGSN - ISNCC2020isncc-conf.org\n",
      "\n",
      "18 hrs6 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "https://thegradient.pub/an-epidemic-of-ai-misinformation/\n",
      "\n",
      "An Epidemic of AI Misinformationthegradient.pub\n",
      "\n",
      "January 10 at 2:50 PM49 · Like · 4 Comments · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "LEEDS Uni: Lecturer or Associate Professor, Artificial Intelligence and Data Science, deadline 5 Feb 2020 https://www.jobs.ac.uk/job/BXU092/lecturer-or-associate-professor-in-computer-science£41-59K p.a. full-time permanent post, deadline for applications: 5.2.2020we are seeking outstanding... More\n",
      "\n",
      "Lecturer or Associate Professor in Computer Science at University of Leedsjobs.ac.uk\n",
      "\n",
      "18 hrs20 · Like · 1 Comment · Full Story\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in els: \n",
    "    soup = BeautifulSoup(el.get_attribute(\"innerHTML\"), 'html.parser')\n",
    "    aa = soup.find_all(lambda x: x.has_attr('data-ft'))\n",
    "    for a in aa:\n",
    "        print(a.text)\n",
    "        print()\n",
    "    print(\"\\n{}\\n\".format(42*\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for tag in soup:\n",
    "    print(tag.has_attr('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = soup.find_all(lambda x: x.has_attr('data-ft'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEEDS Uni: Lecturer or Associate Professor, Artificial Intelligence and Data Science, deadline 5 Feb 2020 https://www.jobs.ac.uk/job/BXU092/lecturer-or-associate-professor-in-computer-science£41-59K p.a. full-time permanent post, deadline for applications: 5.2.2020we are seeking outstanding... More\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Lecturer or Associate Professor in Computer Science at University of Leedsjobs.ac.uk\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "18 hrs20 · Like · 1 Comment · Full Story\n",
      "\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in aa:\n",
    "    print(a.text)\n",
    "    print(\"\\n{}\\n\".format(42*\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yesterday at 5:01 PM\n",
    "Just now · \n",
    "1 min \n",
    "1 hr \n",
    "XX hrs\n",
    "2 mins "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
